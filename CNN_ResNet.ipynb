{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOPfrndSru79iX18qE1XEEo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/robinpats182/Computer-Vision-CNN-Essentials/blob/main/CNN_ResNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I3VZVPb4KKhG"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, Model\n",
        "\n",
        "# Define the residual block\n",
        "# We define a ResidualBlock class that inherits from the layers.Layer class.\n",
        "# The ResidualBlock class contains two convolutional layers with batch normalization and ReLU activation functions\n",
        "class ResidualBlock(layers.Layer):\n",
        "    def __init__(self, filters):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.conv1 = layers.Conv2D(filters, kernel_size=(3, 3), strides=(1, 1), padding='same')\n",
        "        self.bn1 = layers.BatchNormalization()\n",
        "        self.relu = layers.ReLU()\n",
        "        self.conv2 = layers.Conv2D(filters, kernel_size=(3, 3), strides=(1, 1), padding='same')\n",
        "        self.bn2 = layers.BatchNormalization()\n",
        "\n",
        "    ## The call method implements the forward pass, including the residual connection,\n",
        "    #where the input is added to the output before applying the ReLU activation function.\n",
        "    def call(self, inputs):\n",
        "        x = self.conv1(inputs)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.relu(x + inputs)  # Residual connection\n",
        "        return x\n",
        "\n",
        "# Define the CNN model with residual connections\n",
        "#we define the ResidualCNN model that inherits from the Model class.\n",
        "#It consists of a convolutional layer followed by batch normalization and ReLU activation.\n",
        "#The model also includes two instances of the ResidualBlock class, followed by a flatten layer and a fully connected softmax layer.\n",
        "class ResidualCNN(Model):\n",
        "    def __init__(self):\n",
        "        super(ResidualCNN, self).__init__()\n",
        "        self.conv = layers.Conv2D(64, kernel_size=(3, 3), strides=(1, 1), padding='same')\n",
        "        self.bn = layers.BatchNormalization()\n",
        "        self.relu = layers.ReLU()\n",
        "        self.res_block1 = ResidualBlock(64)\n",
        "        self.res_block2 = ResidualBlock(64)\n",
        "        self.flatten = layers.Flatten()\n",
        "        self.fc = layers.Dense(10, activation='softmax')\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.conv(inputs)\n",
        "        x = self.bn(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.res_block1(x)\n",
        "        x = self.res_block2(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "# Load and preprocess the MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "x_train = x_train.reshape(-1, 28, 28, 1) / 255.0\n",
        "x_test = x_test.reshape(-1, 28, 28, 1) / 255.0\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes=10)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes=10)\n",
        "\n",
        "# Create an instance of the ResidualCNN model\n",
        "model = ResidualCNN()\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, batch_size=500, epochs=5, validation_data=(x_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, Model\n",
        "\n",
        "# Define the residual block\n",
        "# We define a ResidualBlock class that inherits from the layers.Layer class.\n",
        "# The ResidualBlock class contains two convolutional layers with batch normalization and ReLU activation functions\n",
        "class ResidualBlock(layers.Layer):\n",
        "    def __init__(self, filters):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.conv1 = layers.Conv2D(filters, kernel_size=(3, 3), strides=(1, 1), padding='same')\n",
        "        self.bn1 = layers.BatchNormalization()\n",
        "        self.relu = layers.ReLU()\n",
        "        self.conv2 = layers.Conv2D(filters, kernel_size=(3, 3), strides=(1, 1), padding='same')\n",
        "        self.bn2 = layers.BatchNormalization()\n",
        "\n",
        "    ## The call method implements the forward pass, including the residual connection,\n",
        "    #where the input is added to the output before applying the ReLU activation function.\n",
        "    def call(self, inputs):\n",
        "        x = self.conv1(inputs)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.relu(x + inputs)  # Residual connection\n",
        "        return x\n",
        "\n",
        "# Define the CNN model with residual connections\n",
        "#we define the ResidualCNN model that inherits from the Model class.\n",
        "#It consists of a convolutional layer followed by batch normalization and ReLU activation.\n",
        "#The model also includes two instances of the ResidualBlock class, followed by a flatten layer and a fully connected softmax layer.\n",
        "class ResidualCNN(Model):\n",
        "    def __init__(self):\n",
        "        super(ResidualCNN, self).__init__()\n",
        "        self.conv = layers.Conv2D(64, kernel_size=(3, 3), strides=(1, 1), padding='same')\n",
        "        self.bn = layers.BatchNormalization()\n",
        "        self.relu = layers.ReLU()\n",
        "        self.res_block1 = ResidualBlock(64)\n",
        "        self.res_block2 = ResidualBlock(64)\n",
        "        self.flatten = layers.Flatten()\n",
        "        self.fc = layers.Dense(10, activation='softmax')\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.conv(inputs)\n",
        "        x = self.bn(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.res_block1(x)\n",
        "        x = self.res_block2(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.fc(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "VhBsE0wgKX-n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "x_train = x_train.reshape(-1, 28, 28, 1) / 255.0\n",
        "x_test = x_test.reshape(-1, 28, 28, 1) / 255.0\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes=10)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JkT0ByOWKg8N",
        "outputId": "e8466e5f-9399-47d9-b310-ce398ec33a2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = ResidualCNN()\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, batch_size=500, epochs=12, validation_data=(x_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PHeY2rQK5AJ",
        "outputId": "cd2afe2f-7cf4-4c5a-f12e-597feceeff58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/12\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 108ms/step - accuracy: 0.7178 - loss: 0.7670 - val_accuracy: 0.8670 - val_loss: 0.3613\n",
            "Epoch 2/12\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 103ms/step - accuracy: 0.8923 - loss: 0.3038 - val_accuracy: 0.8948 - val_loss: 0.2914\n",
            "Epoch 3/12\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 105ms/step - accuracy: 0.9182 - loss: 0.2268 - val_accuracy: 0.9095 - val_loss: 0.2527\n",
            "Epoch 4/12\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 104ms/step - accuracy: 0.9307 - loss: 0.1911 - val_accuracy: 0.9130 - val_loss: 0.2471\n",
            "Epoch 5/12\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 103ms/step - accuracy: 0.9425 - loss: 0.1566 - val_accuracy: 0.9176 - val_loss: 0.2355\n",
            "Epoch 6/12\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 101ms/step - accuracy: 0.9554 - loss: 0.1251 - val_accuracy: 0.9210 - val_loss: 0.2549\n",
            "Epoch 7/12\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 101ms/step - accuracy: 0.9665 - loss: 0.0942 - val_accuracy: 0.9111 - val_loss: 0.2902\n",
            "Epoch 8/12\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 102ms/step - accuracy: 0.9710 - loss: 0.0794 - val_accuracy: 0.9156 - val_loss: 0.2973\n",
            "Epoch 9/12\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 102ms/step - accuracy: 0.9816 - loss: 0.0521 - val_accuracy: 0.9158 - val_loss: 0.3316\n",
            "Epoch 10/12\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 102ms/step - accuracy: 0.9864 - loss: 0.0395 - val_accuracy: 0.9168 - val_loss: 0.3755\n",
            "Epoch 11/12\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 103ms/step - accuracy: 0.9882 - loss: 0.0328 - val_accuracy: 0.9131 - val_loss: 0.4256\n",
            "Epoch 12/12\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 102ms/step - accuracy: 0.9912 - loss: 0.0259 - val_accuracy: 0.9160 - val_loss: 0.4656\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x79ebac4d5b20>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
        "accuracy\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xzf9a-b4LYDk",
        "outputId": "7d8d5d95-f0e8-4397-d0af-56ebd83a68fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9160000085830688"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Kmi38AxMM4-t"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}